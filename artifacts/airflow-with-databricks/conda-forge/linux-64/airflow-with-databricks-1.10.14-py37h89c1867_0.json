{
 "about": {
  "channels": [
   "https://conda.anaconda.org/conda-forge",
   "https://repo.anaconda.com/pkgs/main"
  ],
  "conda_build_version": "3.21.4",
  "conda_private": false,
  "conda_version": "4.9.2",
  "description": "Use airflow to author workflows as directed acyclic graphs (DAGs)\nof tasks. The airflow scheduler executes your tasks on an array of\nworkers while following the specified dependencies. Rich command\nline utilities make performing complex surgeries on DAGs a snap.\nThe rich user interface makes it easy to visualize pipelines\nrunning in production, monitor progress, and troubleshoot issues\nwhen needed.\n\nWhen workflows are defined as code, they become more maintainable,\nversionable, testable, and collaborative.\n",
  "dev_url": "https://github.com/apache/airflow",
  "doc_url": "http://pythonhosted.org/airflow/profiling.html",
  "env_vars": {
   "CIO_TEST": "<not set>"
  },
  "extra": {
   "copy_test_source_files": true,
   "final": true,
   "parent_recipe": {
    "name": "airflow-split",
    "path": "/home/conda/recipe_root",
    "version": "1.10.14"
   },
   "recipe-maintainers": [
    "sodre",
    "halldc",
    "xylar"
   ]
  },
  "home": "http://airflow.apache.org",
  "identifiers": [],
  "keywords": [],
  "license": "Apache-2.0",
  "license_file": "LICENSE",
  "root_pkgs": [
   "zstd 1.4.8 ha95c52a_1",
   "zlib 1.2.11 h516909a_1010",
   "importlib_metadata 3.4.0 hd8ed1ab_0",
   "gettext 0.19.8.1 h0b5b191_1005",
   "liblief 0.10.1 he1b5a44_2",
   "ncurses 6.2 h58526e2_4",
   "tk 8.6.10 h21135ba_1",
   "libarchive 3.5.1 h3f442fb_1",
   "anaconda-client 1.7.2 py_0",
   "_openmp_mutex 4.5 1_gnu",
   "pyopenssl 20.0.1 pyhd8ed1ab_0",
   "libgomp 9.3.0 h2828fa1_18",
   "ca-certificates 2020.12.5 ha878542_0",
   "beautifulsoup4 4.9.3 pyhb0f4dca_0",
   "lzo 2.10 h516909a_1000",
   "jupyter_core 4.7.1 py38h578d9bd_0",
   "requests 2.25.1 pyhd3deb0d_0",
   "urllib3 1.26.3 pyhd8ed1ab_0",
   "pyyaml 5.4.1 py38h497a2fe_0",
   "clyent 1.2.2 py_1",
   "libnghttp2 1.43.0 h812cca2_0",
   "expat 2.2.10 h9c3ff4c_0",
   "cryptography 3.3.1 py38h2b97feb_1",
   "libiconv 1.16 h516909a_0",
   "patch 2.7.6 h7f98852_1002",
   "certifi 2020.12.5 py38h578d9bd_1",
   "ipython_genutils 0.2.0 py_1",
   "pip 21.0.1 pyhd8ed1ab_0",
   "yaml 0.2.5 h516909a_0",
   "brotlipy 0.7.0 py38h497a2fe_1001",
   "pcre 8.44 he1b5a44_0",
   "python 3.8.6 hffdb5ce_5_cpython",
   "filelock 3.0.12 pyh9f0ad1d_0",
   "wheel 0.36.2 pyhd3deb0d_0",
   "libffi 3.3 h58526e2_2",
   "_libgcc_mutex 0.1 conda_forge",
   "jinja2 2.11.3 pyh44b312d_0",
   "perl 5.32.0 h36c2ea0_0",
   "setuptools 49.6.0 py38h578d9bd_3",
   "pysocks 1.7.1 py38h578d9bd_3",
   "py-lief 0.10.1 py38h348cfbe_2",
   "lz4-c 1.9.3 h9c3ff4c_0",
   "conda 4.9.2 py38h578d9bd_0",
   "libssh2 1.9.0 hab1572f_5",
   "tqdm 4.56.0 pyhd8ed1ab_0",
   "psutil 5.8.0 py38h497a2fe_1",
   "traitlets 5.0.5 py_0",
   "xz 5.2.5 h516909a_1",
   "readline 8.0 he28a2e2_2",
   "soupsieve 2.0.1 py_1",
   "markupsafe 1.1.1 py38h497a2fe_3",
   "pyrsistent 0.17.3 py38h497a2fe_2",
   "idna 2.10 pyh9f0ad1d_0",
   "nbformat 5.1.2 pyhd8ed1ab_1",
   "conda-package-handling 1.7.2 py38h8df0ef7_0",
   "zipp 3.4.0 py_0",
   "c-ares 1.17.1 h36c2ea0_0",
   "su-exec 0.2 h516909a_1002",
   "importlib-metadata 3.4.0 py38h578d9bd_0",
   "curl 7.71.1 he644dc0_8",
   "cffi 1.14.4 py38ha65f79e_1",
   "ruamel_yaml 0.15.80 py38h497a2fe_1004",
   "pycosat 0.6.3 py38h497a2fe_1006",
   "tini 0.18.0 h14c3975_1001",
   "patchelf 0.11 he1b5a44_0",
   "openssl 1.1.1i h7f98852_0",
   "python_abi 3.8 1_cp38",
   "attrs 20.3.0 pyhd3deb0d_0",
   "sqlite 3.34.0 h74cdb3f_0",
   "libev 4.33 h516909a_1",
   "krb5 1.17.2 h926e7f8_0",
   "conda-build 3.21.4 py38h578d9bd_0",
   "ripgrep 12.1.1 h516909a_1",
   "bzip2 1.0.8 h7f98852_4",
   "libstdcxx-ng 9.3.0 h6de172a_18",
   "six 1.15.0 pyh9f0ad1d_0",
   "git 2.30.0 pl5320h014a29a_0",
   "jsonschema 3.2.0 py_2",
   "libcurl 7.71.1 hcdd3856_8",
   "chardet 4.0.0 py38h578d9bd_1",
   "python-libarchive-c 2.9 py38h578d9bd_2",
   "libedit 3.1.20191231 he28a2e2_2",
   "glob2 0.7 py_0",
   "pycparser 2.20 pyh9f0ad1d_2",
   "ld_impl_linux-64 2.35.1 hea4e1c9_2",
   "libxml2 2.9.10 h72842e0_3",
   "pkginfo 1.7.0 pyhd8ed1ab_0",
   "pytz 2021.1 pyhd8ed1ab_0",
   "libgcc-ng 9.3.0 h2828fa1_18",
   "python-dateutil 2.8.1 py_0",
   "icu 68.1 h58526e2_0",
   "click 7.1.2 pyh9f0ad1d_0",
   "conda-forge-ci-setup 3.7.1 py38hcd7a344_0",
   "oniguruma 6.9.3 h36c2ea0_0",
   "shyaml 0.6.2 pyhd3deb0d_0",
   "conda-env 2.6.0 1",
   "jq 1.6 h36c2ea0_1000"
  ],
  "summary": "Airflow is a platform to programmatically author, schedule and monitor\nworkflows\n",
  "tags": []
 },
 "conda_build_config": {
  "CI": "azure",
  "c_compiler": "gcc",
  "cdt_name": "cos6",
  "channel_sources": "conda-forge,defaults",
  "channel_targets": "conda-forge main",
  "cpu_optimization_target": "nocona",
  "cran_mirror": "https://cran.r-project.org",
  "cxx_compiler": "gxx",
  "docker_image": "quay.io/condaforge/linux-anvil-comp7",
  "extend_keys": [
   "pin_run_as_build",
   "extend_keys",
   "ignore_build_only_deps",
   "ignore_version"
  ],
  "fortran_compiler": "gfortran",
  "ignore_build_only_deps": [
   "numpy",
   "python"
  ],
  "lua": "5",
  "numpy": "1.16",
  "perl": "5.26.2",
  "pin_run_as_build": {
   "python": {
    "max_pin": "x.x",
    "min_pin": "x.x"
   },
   "r-base": {
    "max_pin": "x.x",
    "min_pin": "x.x"
   }
  },
  "python": "3.7.* *_cpython",
  "r_base": "3.5",
  "target_platform": "linux-64",
  "zip_keys": [
   [
    "cdt_name",
    "docker_image"
   ]
  ]
 },
 "files": [],
 "index": {
  "arch": "x86_64",
  "build": "py37h89c1867_0",
  "build_number": 0,
  "depends": [
   "airflow >=1.10.14,<1.10.15.0a0",
   "python >=3.7,<3.8.0a0",
   "python_abi 3.7.* *_cp37m",
   "requests >=2.20.0,<3"
  ],
  "license": "Apache-2.0",
  "name": "airflow-with-databricks",
  "platform": "linux",
  "subdir": "linux-64",
  "timestamp": 1612935888453,
  "version": "1.10.14"
 },
 "metadata_version": 1,
 "name": "airflow-with-databricks",
 "raw_recipe": "# This file created by conda-build 3.21.4\n# ------------------------------------------------\n\npackage:\n  name: airflow-with-databricks\n  version: 1.10.14\nsource:\n  fn: airflow-1.10.14.tar.gz\n  sha256: f5e5a872788248b178b5dfc822bde7ced5e65b3b3436483a4e352d746cacc28b\n  url: https://github.com/apache/incubator-airflow/archive/1.10.14.tar.gz\nbuild:\n  noarch: false\n  noarch_python: false\n  number: '0'\n  string: py37h89c1867_0\nrequirements:\n  host:\n    - _libgcc_mutex 0.1 conda_forge\n    - _openmp_mutex 4.5 1_gnu\n    - ca-certificates 2020.12.5 ha878542_0\n    - ld_impl_linux-64 2.35.1 hea4e1c9_2\n    - libffi 3.3 h58526e2_2\n    - libgcc-ng 9.3.0 h2828fa1_18\n    - libgomp 9.3.0 h2828fa1_18\n    - libstdcxx-ng 9.3.0 h6de172a_18\n    - ncurses 6.2 h58526e2_4\n    - openssl 1.1.1i h7f98852_0\n    - python 3.7.9 hffdb5ce_0_cpython\n    - readline 8.0 he28a2e2_2\n    - sqlite 3.34.0 h74cdb3f_0\n    - tk 8.6.10 h21135ba_1\n    - xz 5.2.5 h516909a_1\n    - zlib 1.2.11 h516909a_1010\n  run:\n    - airflow >=1.10.14,<1.10.15.0a0\n    - python >=3.7,<3.8.0a0\n    - python_abi 3.7.* *_cp37m\n    - requests >=2.20.0,<3\ntest:\n  imports:\n    - airflow\n    - airflow.contrib.hooks.databricks_hook\n    - requests\nabout:\n  description: 'Use airflow to author workflows as directed acyclic graphs (DAGs)\n\n    of tasks. The airflow scheduler executes your tasks on an array of\n\n    workers while following the specified dependencies. Rich command\n\n    line utilities make performing complex surgeries on DAGs a snap.\n\n    The rich user interface makes it easy to visualize pipelines\n\n    running in production, monitor progress, and troubleshoot issues\n\n    when needed.\n\n\n    When workflows are defined as code, they become more maintainable,\n\n    versionable, testable, and collaborative.\n\n    '\n  dev_url: https://github.com/apache/airflow\n  doc_url: http://pythonhosted.org/airflow/profiling.html\n  home: http://airflow.apache.org\n  license: Apache-2.0\n  license_file: LICENSE\n  summary: 'Airflow is a platform to programmatically author, schedule and monitor\n\n    workflows\n\n    '\nextra:\n  copy_test_source_files: true\n  final: true\n  recipe-maintainers:\n    - halldc\n    - sodre\n    - xylar\n",
 "rendered_recipe": {
  "about": {
   "description": "Use airflow to author workflows as directed acyclic graphs (DAGs)\nof tasks. The airflow scheduler executes your tasks on an array of\nworkers while following the specified dependencies. Rich command\nline utilities make performing complex surgeries on DAGs a snap.\nThe rich user interface makes it easy to visualize pipelines\nrunning in production, monitor progress, and troubleshoot issues\nwhen needed.\n\nWhen workflows are defined as code, they become more maintainable,\nversionable, testable, and collaborative.\n",
   "dev_url": "https://github.com/apache/airflow",
   "doc_url": "http://pythonhosted.org/airflow/profiling.html",
   "home": "http://airflow.apache.org",
   "license": "Apache-2.0",
   "license_file": "LICENSE",
   "summary": "Airflow is a platform to programmatically author, schedule and monitor\nworkflows\n"
  },
  "build": {
   "noarch": false,
   "noarch_python": false,
   "number": "0",
   "string": "py37h89c1867_0"
  },
  "extra": {
   "copy_test_source_files": true,
   "final": true,
   "recipe-maintainers": [
    "halldc",
    "sodre",
    "xylar"
   ]
  },
  "package": {
   "name": "airflow-with-databricks",
   "version": "1.10.14"
  },
  "requirements": {
   "host": [
    "_libgcc_mutex 0.1 conda_forge",
    "_openmp_mutex 4.5 1_gnu",
    "ca-certificates 2020.12.5 ha878542_0",
    "ld_impl_linux-64 2.35.1 hea4e1c9_2",
    "libffi 3.3 h58526e2_2",
    "libgcc-ng 9.3.0 h2828fa1_18",
    "libgomp 9.3.0 h2828fa1_18",
    "libstdcxx-ng 9.3.0 h6de172a_18",
    "ncurses 6.2 h58526e2_4",
    "openssl 1.1.1i h7f98852_0",
    "python 3.7.9 hffdb5ce_0_cpython",
    "readline 8.0 he28a2e2_2",
    "sqlite 3.34.0 h74cdb3f_0",
    "tk 8.6.10 h21135ba_1",
    "xz 5.2.5 h516909a_1",
    "zlib 1.2.11 h516909a_1010"
   ],
   "run": [
    "airflow >=1.10.14,<1.10.15.0a0",
    "python >=3.7,<3.8.0a0",
    "python_abi 3.7.* *_cp37m",
    "requests >=2.20.0,<3"
   ]
  },
  "source": {
   "fn": "airflow-1.10.14.tar.gz",
   "sha256": "f5e5a872788248b178b5dfc822bde7ced5e65b3b3436483a4e352d746cacc28b",
   "url": "https://github.com/apache/incubator-airflow/archive/1.10.14.tar.gz"
  },
  "test": {
   "imports": [
    "airflow",
    "airflow.contrib.hooks.databricks_hook",
    "requests"
   ]
  }
 },
 "version": "1.10.14"
}