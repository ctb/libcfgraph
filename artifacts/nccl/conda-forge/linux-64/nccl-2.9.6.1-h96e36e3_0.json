{
 "about": {
  "channels": [
   "https://conda.anaconda.org/conda-forge",
   "https://repo.anaconda.com/pkgs/main"
  ],
  "conda_build_version": "3.21.4",
  "conda_private": false,
  "conda_version": "4.10.1",
  "description": "The NVIDIA Collective Communications Library (NCCL) implements multi-GPU\nand multi-node collective communication primitives that are performance\noptimized for NVIDIA GPUs. NCCL provides routines such as all-gather,\nall-reduce, broadcast, reduce, reduce-scatter, that are optimized to\nachieve high bandwidth over PCIe and NVLink high-speed interconnect.\n",
  "dev_url": "https://github.com/NVIDIA/nccl",
  "doc_url": "https://docs.nvidia.com/deeplearning/sdk/nccl-developer-guide/docs/index.html",
  "env_vars": {
   "CIO_TEST": "<not set>"
  },
  "extra": {
   "copy_test_source_files": true,
   "final": true,
   "recipe-maintainers": [
    "jakirkham",
    "leofang"
   ]
  },
  "home": "https://developer.nvidia.com/nccl",
  "identifiers": [],
  "keywords": [],
  "license": "BSD-3-Clause",
  "license_family": "BSD",
  "license_file": "LICENSE.txt",
  "root_pkgs": [
   "conda-build 3.21.4 py38h578d9bd_0",
   "_libgcc_mutex 0.1 conda_forge",
   "bzip2 1.0.8 h7f98852_4",
   "libgcc-ng 9.3.0 h2828fa1_18",
   "setuptools 49.6.0 py38h578d9bd_3",
   "libnghttp2 1.43.0 h812cca2_0",
   "gettext 0.19.8.1 h0b5b191_1005",
   "perl 5.32.0 h36c2ea0_0",
   "patch 2.7.6 h7f98852_1002",
   "attrs 20.3.0 pyhd3deb0d_0",
   "psutil 5.8.0 py38h497a2fe_1",
   "libcurl 7.76.0 hc4aaa36_0",
   "libiconv 1.16 h516909a_0",
   "tini 0.18.0 h14c3975_1001",
   "idna 2.10 pyh9f0ad1d_0",
   "py-lief 0.10.1 py38h348cfbe_2",
   "sqlite 3.35.3 h74cdb3f_0",
   "urllib3 1.26.4 pyhd8ed1ab_0",
   "curl 7.76.0 h979ede3_0",
   "python 3.8.8 hffdb5ce_0_cpython",
   "pycosat 0.6.3 py38h497a2fe_1006",
   "clyent 1.2.2 py_1",
   "ca-certificates 2020.12.5 ha878542_0",
   "six 1.15.0 pyh9f0ad1d_0",
   "openssl 1.1.1k h7f98852_0",
   "brotlipy 0.7.0 py38h497a2fe_1001",
   "ncurses 6.2 h58526e2_4",
   "wheel 0.36.2 pyhd3deb0d_0",
   "pip 21.0.1 pyhd8ed1ab_0",
   "libstdcxx-ng 9.3.0 h6de172a_18",
   "nbformat 5.1.2 pyhd8ed1ab_1",
   "cryptography 3.4.7 py38ha5dfef3_0",
   "tk 8.6.10 h21135ba_1",
   "libedit 3.1.20191231 he28a2e2_2",
   "cffi 1.14.5 py38ha65f79e_0",
   "lz4-c 1.9.3 h9c3ff4c_0",
   "glob2 0.7 py_0",
   "chardet 4.0.0 py38h578d9bd_1",
   "git 2.30.2 pl5320h24fefe6_1",
   "yaml 0.2.5 h516909a_0",
   "icu 68.1 h58526e2_0",
   "python-dateutil 2.8.1 py_0",
   "pkginfo 1.7.0 pyhd8ed1ab_0",
   "pyyaml 5.4.1 py38h497a2fe_0",
   "filelock 3.0.12 pyh9f0ad1d_0",
   "krb5 1.17.2 h926e7f8_0",
   "tqdm 4.59.0 pyhd8ed1ab_0",
   "importlib-metadata 3.10.0 py38h578d9bd_0",
   "libxml2 2.9.10 h72842e0_3",
   "zlib 1.2.11 h516909a_1010",
   "ipython_genutils 0.2.0 py_1",
   "conda-package-handling 1.7.2 py38h8df0ef7_0",
   "libgomp 9.3.0 h2828fa1_18",
   "su-exec 0.2 h516909a_1002",
   "certifi 2020.12.5 py38h578d9bd_1",
   "pyrsistent 0.17.3 py38h497a2fe_2",
   "libssh2 1.9.0 ha56f1ee_6",
   "traitlets 5.0.5 py_0",
   "ld_impl_linux-64 2.35.1 hea4e1c9_2",
   "libarchive 3.5.1 h3f442fb_1",
   "readline 8.0 he28a2e2_2",
   "beautifulsoup4 4.9.3 pyhb0f4dca_0",
   "python-libarchive-c 2.9 py38h578d9bd_2",
   "ruamel_yaml 0.15.80 py38h497a2fe_1004",
   "pcre 8.44 he1b5a44_0",
   "anaconda-client 1.7.2 py_0",
   "liblief 0.10.1 he1b5a44_2",
   "libev 4.33 h516909a_1",
   "pysocks 1.7.1 py38h578d9bd_3",
   "jinja2 2.11.3 pyh44b312d_0",
   "zstd 1.4.9 ha95c52a_0",
   "pytz 2021.1 pyhd8ed1ab_0",
   "expat 2.3.0 h9c3ff4c_0",
   "zipp 3.4.1 pyhd8ed1ab_0",
   "requests 2.25.1 pyhd3deb0d_0",
   "python_abi 3.8 1_cp38",
   "patchelf 0.11 he1b5a44_0",
   "_openmp_mutex 4.5 1_gnu",
   "ripgrep 12.1.1 h516909a_1",
   "pyopenssl 20.0.1 pyhd8ed1ab_0",
   "pycparser 2.20 pyh9f0ad1d_2",
   "jsonschema 3.2.0 pyhd8ed1ab_3",
   "lzo 2.10 h516909a_1000",
   "c-ares 1.17.1 h7f98852_1",
   "markupsafe 1.1.1 py38h497a2fe_3",
   "soupsieve 2.0.1 py_1",
   "jupyter_core 4.7.1 py38h578d9bd_0",
   "xz 5.2.5 h516909a_1",
   "libffi 3.3 h58526e2_2",
   "jq 1.6 h36c2ea0_1000",
   "click 7.1.2 pyh9f0ad1d_0",
   "conda-env 2.6.0 1",
   "conda 4.10.1 py38h578d9bd_0",
   "conda-forge-ci-setup 3.9.3 py38h7bc8238_0",
   "shyaml 0.6.2 pyhd3deb0d_0",
   "oniguruma 6.9.7.1 h7f98852_0"
  ],
  "summary": "Optimized primitives for collective multi-GPU communication",
  "tags": []
 },
 "conda_build_config": {
  "CI": "azure",
  "c_compiler": "gcc",
  "c_compiler_version": "7",
  "cdt_name": "cos7",
  "channel_sources": "conda-forge,defaults",
  "channel_targets": "conda-forge main",
  "cpu_optimization_target": "nocona",
  "cran_mirror": "https://cran.r-project.org",
  "cuda_compiler": "nvcc",
  "cuda_compiler_version": "11.0",
  "cudnn": "7",
  "cxx_compiler": "gxx",
  "cxx_compiler_version": "7",
  "docker_image": "quay.io/condaforge/linux-anvil-cuda:11.0",
  "extend_keys": [
   "ignore_version",
   "ignore_build_only_deps",
   "pin_run_as_build",
   "extend_keys"
  ],
  "fortran_compiler": "gfortran",
  "ignore_build_only_deps": [
   "numpy",
   "python"
  ],
  "lua": "5",
  "numpy": "1.16",
  "perl": "5.26.2",
  "pin_run_as_build": {
   "python": {
    "max_pin": "x.x",
    "min_pin": "x.x"
   },
   "r-base": {
    "max_pin": "x.x",
    "min_pin": "x.x"
   }
  },
  "python": "3.8",
  "r_base": "3.5",
  "target_platform": "linux-64",
  "zip_keys": [
   [
    "cuda_compiler_version",
    "cdt_name",
    "docker_image"
   ],
   [
    "c_compiler_version",
    "cxx_compiler_version"
   ]
  ]
 },
 "files": [
  "include/nccl.h",
  "include/nccl_net.h",
  "lib/libnccl.so",
  "lib/libnccl.so.2",
  "lib/libnccl.so.2.9.6",
  "lib/pkgconfig/nccl.pc"
 ],
 "index": {
  "arch": "x86_64",
  "build": "h96e36e3_0",
  "build_number": 0,
  "depends": [
   "__glibc >=2.17",
   "cudatoolkit 11.0|11.0.*",
   "libgcc-ng >=7.5.0",
   "libstdcxx-ng >=7.5.0"
  ],
  "license": "BSD-3-Clause",
  "license_family": "BSD",
  "name": "nccl",
  "platform": "linux",
  "subdir": "linux-64",
  "timestamp": 1618607967687,
  "version": "2.9.6.1"
 },
 "metadata_version": 1,
 "name": "nccl",
 "raw_recipe": "{% set name = \"nccl\" %}\n{% set version = \"2.9.6-1\" %}\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version|replace(\"-\", \".\") }}\n\nsource:\n  url: https://github.com/NVIDIA/nccl/archive/v{{ version }}.tar.gz\n  sha256: c4b1f5a88f03c0ac8f1dcbe27723cd75cfe051754078d83629efaaed10ce8731\n\nbuild:\n  number: 0\n  skip: true  # [(not linux) or (cuda_compiler_version == \"None\")]\n  run_exports:\n    # xref: https://github.com/NVIDIA/nccl/issues/218\n    - {{ pin_subpackage(name, max_pin=\"x\") }}\n\nrequirements:\n  build:\n    - {{ compiler(\"c\") }}\n    - {{ compiler(\"cxx\") }}\n    - {{ compiler(\"cuda\") }}\n    - make\n\ntest:\n  commands:\n    - test -f \"${PREFIX}/include/nccl.h\"\n    - test -f \"${PREFIX}/lib/libnccl.so\"\n    - test ! -f \"${PREFIX}/lib/libnccl_static.a\"\n\nabout:\n  home: https://developer.nvidia.com/nccl\n  license: BSD-3-Clause\n  license_family: BSD\n  license_file: LICENSE.txt\n  summary: Optimized primitives for collective multi-GPU communication\n\n  description: |\n    The NVIDIA Collective Communications Library (NCCL) implements multi-GPU\n    and multi-node collective communication primitives that are performance\n    optimized for NVIDIA GPUs. NCCL provides routines such as all-gather,\n    all-reduce, broadcast, reduce, reduce-scatter, that are optimized to\n    achieve high bandwidth over PCIe and NVLink high-speed interconnect.\n\n  doc_url: https://docs.nvidia.com/deeplearning/sdk/nccl-developer-guide/docs/index.html\n  dev_url: https://github.com/NVIDIA/nccl\n\nextra:\n  recipe-maintainers:\n    - jakirkham\n    - leofang\n",
 "rendered_recipe": {
  "about": {
   "description": "The NVIDIA Collective Communications Library (NCCL) implements multi-GPU\nand multi-node collective communication primitives that are performance\noptimized for NVIDIA GPUs. NCCL provides routines such as all-gather,\nall-reduce, broadcast, reduce, reduce-scatter, that are optimized to\nachieve high bandwidth over PCIe and NVLink high-speed interconnect.\n",
   "dev_url": "https://github.com/NVIDIA/nccl",
   "doc_url": "https://docs.nvidia.com/deeplearning/sdk/nccl-developer-guide/docs/index.html",
   "home": "https://developer.nvidia.com/nccl",
   "license": "BSD-3-Clause",
   "license_family": "BSD",
   "license_file": "LICENSE.txt",
   "summary": "Optimized primitives for collective multi-GPU communication"
  },
  "build": {
   "number": "0",
   "run_exports": [
    "nccl >=2.9.6.1,<3.0a0"
   ],
   "string": "h96e36e3_0"
  },
  "extra": {
   "copy_test_source_files": true,
   "final": true,
   "recipe-maintainers": [
    "jakirkham",
    "leofang"
   ]
  },
  "package": {
   "name": "nccl",
   "version": "2.9.6.1"
  },
  "requirements": {
   "build": [
    "_libgcc_mutex 0.1 conda_forge",
    "_openmp_mutex 4.5 1_gnu",
    "_sysroot_linux-64_curr_repodata_hack 3 ha9d2b57_10",
    "binutils_impl_linux-64 2.35.1 h193b22a_2",
    "binutils_linux-64 2.35 h67ddf6f_30",
    "gcc_impl_linux-64 7.5.0 hda68d29_13",
    "gcc_linux-64 7.5.0 h47867f9_30",
    "gxx_impl_linux-64 7.5.0 h64c220c_13",
    "gxx_linux-64 7.5.0 h555fc39_30",
    "kernel-headers_linux-64 3.10.0 h77966d4_10",
    "ld_impl_linux-64 2.35.1 hea4e1c9_2",
    "libgcc-ng 9.3.0 h2828fa1_19",
    "libgomp 9.3.0 h2828fa1_19",
    "libstdcxx-ng 9.3.0 h6de172a_19",
    "make 4.3 hd18ef5c_1",
    "nvcc_linux-64 11.0 h96e36e3_12",
    "sed 4.8 he412f7d_0",
    "sysroot_linux-64 2.17 h77966d4_10"
   ],
   "host": [
    "_libgcc_mutex 0.1 conda_forge",
    "_openmp_mutex 4.5 1_gnu",
    "cudatoolkit 11.0.3 h15472ef_8",
    "libgcc-ng 9.3.0 h2828fa1_19",
    "libgomp 9.3.0 h2828fa1_19",
    "libstdcxx-ng 9.3.0 h6de172a_19"
   ],
   "run": [
    "__glibc >=2.17",
    "cudatoolkit 11.0|11.0.*",
    "libgcc-ng >=7.5.0",
    "libstdcxx-ng >=7.5.0"
   ]
  },
  "source": {
   "sha256": "c4b1f5a88f03c0ac8f1dcbe27723cd75cfe051754078d83629efaaed10ce8731",
   "url": "https://github.com/NVIDIA/nccl/archive/v2.9.6-1.tar.gz"
  },
  "test": {
   "commands": [
    "test -f \"${PREFIX}/include/nccl.h\"",
    "test -f \"${PREFIX}/lib/libnccl.so\"",
    "test ! -f \"${PREFIX}/lib/libnccl_static.a\""
   ]
  }
 },
 "version": "2.9.6.1"
}