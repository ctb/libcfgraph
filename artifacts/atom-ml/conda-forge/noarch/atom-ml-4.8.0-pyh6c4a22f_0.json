{
 "about": {
  "channels": [
   "https://conda.anaconda.org/conda-forge",
   "https://repo.anaconda.com/pkgs/main"
  ],
  "conda_build_version": "3.21.4",
  "conda_private": false,
  "conda_version": "4.10.3",
  "description": "During the exploration phase of a machine learning project, a data\nscientist tries to find the optimal pipeline for his specific use case.\nThis usually involves applying standard data cleaning steps, creating\nor selecting useful features, trying out different models, etc. Testing\nmultiple pipelines requires many lines of code, and writing it all in\nthe same notebook often makes it long and cluttered. On the other hand,\nusing multiple notebooks makes it harder to compare the results and to\nkeep an overview. On top of that, refactoring the code for every test\ncan be time-consuming. How many times have you conducted the same action\nto pre-process a raw dataset? How many times have you copy-and-pasted\ncode from an old repository to re-use it in a new use case?\n\nATOM is here to help solve these common issues. The package acts as\na wrapper of the whole machine learning pipeline, helping the data\nscientist to rapidly find a good model for his problem. Avoid\nendless imports and documentation lookups. Avoid rewriting the same\ncode over and over again. With just a few lines of code, it's now\npossible to perform basic data cleaning steps, select relevant\nfeatures and compare the performance of multiple models on a given\ndataset, providing quick insights on which pipeline performs best\nfor the task at hand.\n",
  "dev_url": "http://github.com/tvdboom/ATOM/tree/development",
  "doc_url": "https://tvdboom.github.io/ATOM/",
  "env_vars": {
   "CIO_TEST": "<not set>"
  },
  "extra": {
   "copy_test_source_files": true,
   "final": true,
   "recipe-maintainers": [
    "tvdboom"
   ]
  },
  "home": "http://github.com/tvdboom/ATOM",
  "identifiers": [],
  "keywords": [],
  "license": "MIT",
  "license_file": "LICENSE",
  "root_pkgs": [
   "tini 0.18.0 h14c3975_1001",
   "libssh2 1.10.0 ha56f1ee_0",
   "wheel 0.37.0 pyhd8ed1ab_1",
   "jinja2 3.0.1 pyhd8ed1ab_0",
   "liblief 0.11.5 h9c3ff4c_0",
   "cffi 1.14.6 py38h3931269_1",
   "xz 5.2.5 h516909a_1",
   "pyopenssl 20.0.1 pyhd8ed1ab_0",
   "libgomp 11.2.0 h1d223b6_8",
   "ld_impl_linux-64 2.36.1 hea4e1c9_2",
   "python-dateutil 2.8.2 pyhd8ed1ab_0",
   "yaml 0.2.5 h516909a_0",
   "sqlite 3.36.0 h9cd32fc_1",
   "pytz 2021.1 pyhd8ed1ab_0",
   "pkginfo 1.7.1 pyhd8ed1ab_0",
   "ipython_genutils 0.2.0 py_1",
   "pycosat 0.6.3 py38h497a2fe_1006",
   "expat 2.4.1 h9c3ff4c_0",
   "lz4-c 1.9.3 h9c3ff4c_1",
   "idna 3.1 pyhd3deb0d_0",
   "requests 2.26.0 pyhd8ed1ab_0",
   "conda-package-handling 1.7.3 py38h497a2fe_0",
   "jupyter_core 4.8.1 py38h578d9bd_0",
   "git 2.33.0 pl5321hc30692c_0",
   "anaconda-client 1.7.2 pyhd8ed1ab_1",
   "traitlets 5.1.0 pyhd8ed1ab_0",
   "zlib 1.2.11 h516909a_1010",
   "ripgrep 13.0.0 habb4d0f_0",
   "filelock 3.0.12 pyh9f0ad1d_0",
   "libarchive 3.5.2 hccf745f_0",
   "pyrsistent 0.17.3 py38h497a2fe_2",
   "pcre2 10.37 h032f7d1_0",
   "perl 5.32.1 0_h7f98852_perl5",
   "cryptography 3.4.7 py38ha5dfef3_0",
   "lzo 2.10 h516909a_1000",
   "libnghttp2 1.43.0 h812cca2_0",
   "krb5 1.19.2 hcc1bbae_0",
   "icu 68.1 h58526e2_0",
   "tk 8.6.11 h27826a3_1",
   "libgcc-ng 11.2.0 h1d223b6_8",
   "nbformat 5.1.3 pyhd8ed1ab_0",
   "_openmp_mutex 4.5 1_gnu",
   "libiconv 1.16 h516909a_0",
   "ncurses 6.2 h58526e2_4",
   "bzip2 1.0.8 h7f98852_4",
   "python 3.8.12 hb7a2778_0_cpython",
   "clyent 1.2.2 py_1",
   "six 1.16.0 pyh6c4a22f_0",
   "libcurl 7.79.0 h2574ce0_0",
   "importlib-metadata 4.8.1 py38h578d9bd_0",
   "conda-build 3.21.4 py38h578d9bd_0",
   "python-libarchive-c 3.1 py38h578d9bd_0",
   "curl 7.79.0 hea6ffbf_0",
   "brotlipy 0.7.0 py38h497a2fe_1001",
   "libxml2 2.9.12 h72842e0_0",
   "gettext 0.19.8.1 h73d1719_1006",
   "libedit 3.1.20191231 he28a2e2_2",
   "charset-normalizer 2.0.0 pyhd8ed1ab_0",
   "urllib3 1.26.6 pyhd8ed1ab_0",
   "psutil 5.8.0 py38h497a2fe_1",
   "setuptools 58.0.4 py38h578d9bd_0",
   "glob2 0.7 py_0",
   "patchelf 0.13 h58526e2_0",
   "libstdcxx-ng 11.2.0 he4da1e4_8",
   "py-lief 0.11.5 py38h709712a_0",
   "soupsieve 2.0.1 py_1",
   "_libgcc_mutex 0.1 conda_forge",
   "libffi 3.4.2 h9c3ff4c_1",
   "attrs 21.2.0 pyhd8ed1ab_0",
   "ruamel_yaml 0.15.80 py38h497a2fe_1004",
   "markupsafe 2.0.1 py38h497a2fe_0",
   "pyyaml 5.4.1 py38h497a2fe_1",
   "zstd 1.5.0 ha95c52a_0",
   "python_abi 3.8 2_cp38",
   "ca-certificates 2021.5.30 ha878542_0",
   "chardet 4.0.0 py38h578d9bd_1",
   "beautifulsoup4 4.10.0 pyha770c72_0",
   "zipp 3.5.0 pyhd8ed1ab_0",
   "readline 8.1 h46c0cb4_0",
   "libev 4.33 h516909a_1",
   "pycparser 2.20 pyh9f0ad1d_2",
   "patch 2.7.6 h7f98852_1002",
   "su-exec 0.2 h516909a_1002",
   "certifi 2021.5.30 py38h578d9bd_0",
   "openssl 1.1.1l h7f98852_0",
   "pip 21.2.4 pyhd8ed1ab_0",
   "jsonschema 3.2.0 pyhd8ed1ab_3",
   "tqdm 4.62.2 pyhd8ed1ab_0",
   "colorama 0.4.4 pyh9f0ad1d_0",
   "pysocks 1.7.1 py38h578d9bd_3",
   "c-ares 1.17.2 h7f98852_0",
   "conda 4.10.3 py38h578d9bd_2",
   "oniguruma 6.9.7.1 h7f98852_0",
   "conda-env 2.6.0 1",
   "shyaml 0.6.2 pyhd3deb0d_0",
   "click 8.0.1 py38h578d9bd_0",
   "jq 1.6 h36c2ea0_1000",
   "conda-forge-ci-setup 3.11.1 py38h904d315_0"
  ],
  "summary": "A Python package for fast exploration of machine learning pipelines",
  "tags": []
 },
 "conda_build_config": {
  "CI": "azure",
  "c_compiler": "gcc",
  "cdt_name": "cos6",
  "channel_sources": "conda-forge,defaults",
  "channel_targets": "conda-forge main",
  "cpu_optimization_target": "nocona",
  "cran_mirror": "https://cran.r-project.org",
  "cxx_compiler": "gxx",
  "docker_image": "quay.io/condaforge/linux-anvil-comp7",
  "extend_keys": [
   "ignore_build_only_deps",
   "extend_keys",
   "pin_run_as_build",
   "ignore_version"
  ],
  "fortran_compiler": "gfortran",
  "ignore_build_only_deps": [
   "python",
   "numpy"
  ],
  "lua": "5",
  "numpy": "1.16",
  "perl": "5.26.2",
  "pin_run_as_build": {
   "python": {
    "max_pin": "x.x",
    "min_pin": "x.x"
   },
   "r-base": {
    "max_pin": "x.x",
    "min_pin": "x.x"
   }
  },
  "python": "3.9.* *_cpython",
  "r_base": "3.5",
  "target_platform": "linux-64",
  "zip_keys": [
   [
    "cdt_name",
    "docker_image"
   ]
  ]
 },
 "files": [
  "site-packages/atom/__init__.py",
  "site-packages/atom/api.py",
  "site-packages/atom/atom.py",
  "site-packages/atom/basemodel.py",
  "site-packages/atom/basepredictor.py",
  "site-packages/atom/basetrainer.py",
  "site-packages/atom/basetransformer.py",
  "site-packages/atom/branch.py",
  "site-packages/atom/data_cleaning.py",
  "site-packages/atom/ensembles.py",
  "site-packages/atom/feature_engineering.py",
  "site-packages/atom/modeloptimizer.py",
  "site-packages/atom/models.py",
  "site-packages/atom/nlp.py",
  "site-packages/atom/pipeline.py",
  "site-packages/atom/plots.py",
  "site-packages/atom/training.py",
  "site-packages/atom/utils.py",
  "site-packages/atom_ml-4.8.0.dist-info/INSTALLER",
  "site-packages/atom_ml-4.8.0.dist-info/LICENSE",
  "site-packages/atom_ml-4.8.0.dist-info/METADATA",
  "site-packages/atom_ml-4.8.0.dist-info/RECORD",
  "site-packages/atom_ml-4.8.0.dist-info/REQUESTED",
  "site-packages/atom_ml-4.8.0.dist-info/WHEEL",
  "site-packages/atom_ml-4.8.0.dist-info/direct_url.json"
 ],
 "index": {
  "arch": null,
  "build": "pyh6c4a22f_0",
  "build_number": 0,
  "depends": [
   "category_encoders",
   "dill",
   "featuretools",
   "gplearn",
   "imbalanced-learn",
   "joblib",
   "matplotlib-base",
   "mlflow",
   "nltk",
   "numpy",
   "pandas",
   "pandas-profiling",
   "python >=3.6",
   "scikit-learn ~=0.24.0",
   "scikit-optimize",
   "scipy",
   "seaborn",
   "shap",
   "tabulate",
   "tpot",
   "tqdm",
   "typeguard",
   "wordcloud"
  ],
  "license": "MIT",
  "name": "atom-ml",
  "noarch": "python",
  "platform": null,
  "subdir": "noarch",
  "timestamp": 1632929337691,
  "version": "4.8.0"
 },
 "metadata_version": 1,
 "name": "atom-ml",
 "raw_recipe": "{% set name = \"atom-ml\" %}\n{% set version = \"4.8.0\" %}\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}\n\nsource:\n  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz\n  sha256: 0cd760cf0f48dbde17500f20bdb413fceef0e4247640b13f88627a87fbb74ee9\n\n\nbuild:\n  number: 0\n  noarch: python\n  script: {{ PYTHON }} -m pip install . --no-deps -vv\n\nrequirements:\n  host:\n    - python >=3.6\n    - pip\n  run:\n    - python >=3.6\n    - numpy\n    - scipy\n    - pandas\n    - pandas-profiling\n    - mlflow\n    - dill\n    - tqdm\n    - joblib\n    - typeguard\n    - tabulate\n    - scikit-learn ~= 0.24.0\n    - scikit-optimize\n    - nltk\n    - tpot\n    - category_encoders\n    - imbalanced-learn\n    - featuretools\n    - gplearn\n    - matplotlib-base\n    - seaborn\n    - shap\n    - wordcloud\n\ntest:\n  requires:\n    - pip\n    - pytest\n    - coverage\n    - python\n    - tensorflow\n    - numpy\n    - scipy\n    - pandas\n    - pandas-profiling\n    - mlflow\n    - dill\n    - tqdm\n    - joblib\n    - typeguard\n    - tabulate\n    - scikit-learn ~= 0.24.0\n    - scikit-optimize\n    - nltk\n    - tpot\n    - category_encoders\n    - imbalanced-learn\n    - featuretools\n    - gplearn\n    - matplotlib-base\n    - seaborn\n    - shap\n    - wordcloud\n    - py-xgboost  # [not win]\n    - lightgbm\n    - catboost\n  source_files:\n    - tests\n  imports:\n    - atom\n  commands:\n    - mkdir tests/files  # Directory to save files during testing\n    - coverage run -m pytest\n\nabout:\n  home: http://github.com/tvdboom/ATOM\n  license: MIT\n  license_file: LICENSE\n  summary: A Python package for fast exploration of machine learning pipelines\n  description: |\n    During the exploration phase of a machine learning project, a data\n    scientist tries to find the optimal pipeline for his specific use case.\n    This usually involves applying standard data cleaning steps, creating\n    or selecting useful features, trying out different models, etc. Testing\n    multiple pipelines requires many lines of code, and writing it all in\n    the same notebook often makes it long and cluttered. On the other hand,\n    using multiple notebooks makes it harder to compare the results and to\n    keep an overview. On top of that, refactoring the code for every test\n    can be time-consuming. How many times have you conducted the same action\n    to pre-process a raw dataset? How many times have you copy-and-pasted\n    code from an old repository to re-use it in a new use case?\n\n    ATOM is here to help solve these common issues. The package acts as\n    a wrapper of the whole machine learning pipeline, helping the data\n    scientist to rapidly find a good model for his problem. Avoid\n    endless imports and documentation lookups. Avoid rewriting the same\n    code over and over again. With just a few lines of code, it's now\n    possible to perform basic data cleaning steps, select relevant\n    features and compare the performance of multiple models on a given\n    dataset, providing quick insights on which pipeline performs best\n    for the task at hand.\n\n  doc_url: https://tvdboom.github.io/ATOM/\n  dev_url: http://github.com/tvdboom/ATOM/tree/development\n\nextra:\n  recipe-maintainers:\n    - tvdboom\n",
 "rendered_recipe": {
  "about": {
   "description": "During the exploration phase of a machine learning project, a data\nscientist tries to find the optimal pipeline for his specific use case.\nThis usually involves applying standard data cleaning steps, creating\nor selecting useful features, trying out different models, etc. Testing\nmultiple pipelines requires many lines of code, and writing it all in\nthe same notebook often makes it long and cluttered. On the other hand,\nusing multiple notebooks makes it harder to compare the results and to\nkeep an overview. On top of that, refactoring the code for every test\ncan be time-consuming. How many times have you conducted the same action\nto pre-process a raw dataset? How many times have you copy-and-pasted\ncode from an old repository to re-use it in a new use case?\n\nATOM is here to help solve these common issues. The package acts as\na wrapper of the whole machine learning pipeline, helping the data\nscientist to rapidly find a good model for his problem. Avoid\nendless imports and documentation lookups. Avoid rewriting the same\ncode over and over again. With just a few lines of code, it's now\npossible to perform basic data cleaning steps, select relevant\nfeatures and compare the performance of multiple models on a given\ndataset, providing quick insights on which pipeline performs best\nfor the task at hand.\n",
   "dev_url": "http://github.com/tvdboom/ATOM/tree/development",
   "doc_url": "https://tvdboom.github.io/ATOM/",
   "home": "http://github.com/tvdboom/ATOM",
   "license": "MIT",
   "license_file": "LICENSE",
   "summary": "A Python package for fast exploration of machine learning pipelines"
  },
  "build": {
   "noarch": "python",
   "number": "0",
   "script": "/home/conda/feedstock_root/build_artifacts/atom-ml_1632928559160/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pla/bin/python -m pip install . --no-deps -vv",
   "string": "pyh6c4a22f_0"
  },
  "extra": {
   "copy_test_source_files": true,
   "final": true,
   "recipe-maintainers": [
    "tvdboom"
   ]
  },
  "package": {
   "name": "atom-ml",
   "version": "4.8.0"
  },
  "requirements": {
   "host": [
    "_libgcc_mutex 0.1 conda_forge",
    "_openmp_mutex 4.5 1_gnu",
    "ca-certificates 2021.5.30 ha878542_0",
    "ld_impl_linux-64 2.36.1 hea4e1c9_2",
    "libffi 3.4.2 h9c3ff4c_4",
    "libgcc-ng 11.2.0 h1d223b6_9",
    "libgomp 11.2.0 h1d223b6_9",
    "libstdcxx-ng 11.2.0 he4da1e4_9",
    "ncurses 6.2 h58526e2_4",
    "openssl 1.1.1l h7f98852_0",
    "pip 21.2.4 pyhd8ed1ab_0",
    "python 3.9.7 hb7a2778_2_cpython",
    "python_abi 3.9 2_cp39",
    "readline 8.1 h46c0cb4_0",
    "setuptools 58.0.4 py39hf3d152e_2",
    "sqlite 3.36.0 h9cd32fc_2",
    "tk 8.6.11 h27826a3_1",
    "tzdata 2021a he74cb21_1",
    "wheel 0.37.0 pyhd8ed1ab_1",
    "xz 5.2.5 h516909a_1",
    "zlib 1.2.11 h516909a_1010"
   ],
   "run": [
    "category_encoders",
    "dill",
    "featuretools",
    "gplearn",
    "imbalanced-learn",
    "joblib",
    "matplotlib-base",
    "mlflow",
    "nltk",
    "numpy",
    "pandas",
    "pandas-profiling",
    "python >=3.6",
    "scikit-learn ~= 0.24.0",
    "scikit-optimize",
    "scipy",
    "seaborn",
    "shap",
    "tabulate",
    "tpot",
    "tqdm",
    "typeguard",
    "wordcloud"
   ]
  },
  "source": {
   "sha256": "0cd760cf0f48dbde17500f20bdb413fceef0e4247640b13f88627a87fbb74ee9",
   "url": "https://pypi.io/packages/source/a/atom-ml/atom-ml-4.8.0.tar.gz"
  },
  "test": {
   "commands": [
    "mkdir tests/files",
    "coverage run -m pytest"
   ],
   "imports": [
    "atom"
   ],
   "requires": [
    "catboost",
    "category_encoders",
    "coverage",
    "dill",
    "featuretools",
    "gplearn",
    "imbalanced-learn",
    "joblib",
    "lightgbm",
    "matplotlib-base",
    "mlflow",
    "nltk",
    "numpy",
    "pandas",
    "pandas-profiling",
    "pip",
    "py-xgboost",
    "pytest",
    "python",
    "scikit-learn ~= 0.24.0",
    "scikit-optimize",
    "scipy",
    "seaborn",
    "shap",
    "tabulate",
    "tensorflow",
    "tpot",
    "tqdm",
    "typeguard",
    "wordcloud"
   ],
   "source_files": [
    "tests"
   ]
  }
 },
 "version": "4.8.0"
}